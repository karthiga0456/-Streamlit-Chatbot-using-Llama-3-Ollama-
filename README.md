Streamlit Chatbot using Llama 3 (Ollama)




Overview
This project is a Chatbot built using Streamlit and Llama 3 from Ollama. It provides a simple web-based UI for interacting with the chatbot.

ğŸš€ Features
âœ… Uses Llama 3 from Ollama for local inference
âœ… Built with Streamlit for an interactive UI
âœ… No external API keys required â€“ runs locally
âœ… Lightweight and easy to set up

ğŸ“Œ Installation
1ï¸âƒ£ Clone the Repository
sh
Copy
Edit
git clone https://github.com/karthiga0456/-Streamlit-Chatbot-using-Llama-3-Ollama-.git
cd Streamlit-Chatbot-using-Llama-3-Ollama

2ï¸âƒ£ Set Up a Virtual Environment
sh
Copy
Edit
python -m venv myenv
source myenv/bin/activate  # On macOS/Linux
myenv\Scripts\activate     # On Windows

3ï¸âƒ£ Install Dependencies
sh
Copy
Edit
pip install -r requirements.txt

4ï¸âƒ£ Install Ollama and Llama 3 Model
sh
Copy
Edit
ollama pull llama3

5ï¸âƒ£ Run the Streamlit App
sh
Copy
Edit
streamlit run app.py
ğŸ–¥ï¸ Usage
1ï¸âƒ£ Open the Streamlit app in your browser.
2ï¸âƒ£ Enter your question in the chat input box.
3ï¸âƒ£ The Llama 3 model will generate a response.

ğŸ”§ Configuration
If you want to modify the chatbot, edit app.py.
Change the model in app.py if you have a different Ollama model installed.
ğŸ“œ License
This project is licensed under the MIT License.
